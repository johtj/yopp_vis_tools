{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import holoviews as hv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "import hvplot.xarray \n",
    "import panel as pn\n",
    "from thredds_crawler.crawl import Crawl\n",
    "import datetime as dt\n",
    "from scipy.interpolate import interp1d,interp2d\n",
    "from bokeh.models import  FixedTicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prep_mod(url):\n",
    "    #opens model file from url as dataset\n",
    "    mod = xr.open_dataset(url)\n",
    "    \n",
    "    #calculate height axis for the model, works for IFS\n",
    "    mod['height'] = mod.zg - mod.zghalf[:, -1]\n",
    "    \n",
    "    #select relevant variable and height axis\n",
    "    mod_ds = mod[['height','ta']]\n",
    "    \n",
    "    #flip the height axis and convert to dataframe\n",
    "    mod_ds = mod_ds.reindex(level=list(reversed(mod_ds.level)))\n",
    "    tot_df = mod_ds.to_dataframe()\n",
    "    \n",
    "    #resample with 6 hour frequency, to match sond frequency \n",
    "    #and remove first point in resulting dataframe\n",
    "    #as it is at point 00:00:00, and the first model point when resampled should occur \n",
    "    #at 01:00:00\n",
    "    df_res = tot_df.swaplevel().unstack().resample('6H').asfreq()\n",
    "    df_res = df_res[1:]\n",
    "    \n",
    "    return df_res\n",
    "    \n",
    "def interpolate_mod(df_res,height):\n",
    "    #create a dummy dataframe with the correct dimensions to hold the results\n",
    "    time = df_res.index.values\n",
    "    dummy = pd.DataFrame('NaN',height,time)\n",
    "\n",
    "    #for each timestep - read for each height axis, interpolate to the new axis\n",
    "    #then add to the dummy dataframe \n",
    "    for i in df_res.index.values:\n",
    "        temp = df_res.loc[i].unstack().T\n",
    "        height_model = temp['height']\n",
    "        temperature = temp['ta']\n",
    "\n",
    "        interpolated = interp1d(height_model,temperature,fill_value=\"extrapolate\")(height)\n",
    "        dummy[i] = interpolated\n",
    "    \n",
    "    \n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_err(mod,obs,hours):\n",
    "    #get model start and end times\n",
    "    st = mod.columns.values[0]\n",
    "    et = mod.columns.values[-1]\n",
    "    \n",
    "    #select relevant slice of observational data and reformat \n",
    "    #to match model format\n",
    "    time_obs = obs.sel(time=slice(st, et)).to_dataframe().unstack()\n",
    "    time_obs.columns = time_obs.columns.droplevel()\n",
    "    time_obs = time_obs.T\n",
    "\n",
    "    #calculate error by combining the model and observation dataframes\n",
    "    #using a set function\n",
    "    comb_func = lambda x,y: x-y\n",
    "    err = mod.combine(time_obs,comb_func)\n",
    "    \n",
    "    #convert to common time axis based on how many hours into the 3 \n",
    "    #day forcast the point is\n",
    "    err.columns = hours\n",
    "    \n",
    "    return err\n",
    "\n",
    "\n",
    "def calc_median(stacked_errors,hours):\n",
    "    medians = []\n",
    "    #calculate median for each timestep \n",
    "    for hour in hours:\n",
    "        hour = hour -1\n",
    "        values_per_time = stacked_errors[:,hour,:]\n",
    "\n",
    "        medians.append(np.nanmedian(values_per_time,axis=0))\n",
    "    \n",
    "    #create new 2D dataset with index height and time, containing\n",
    "    #the median error \n",
    "    plottable= np.stack(medians).T\n",
    "    \n",
    "    return plottable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of urls\n",
    "catalog = \"https://thredds.met.no/thredds/catalog/alertness/YOPP_supersite/ifs-ecmwf/sodankyla/catalog.html\"\n",
    "c = Crawl(catalog, select=['.*20180[23]..00\\.nc'])\n",
    "urls_mod = []\n",
    "for d in c.datasets:\n",
    "    for s in d.services:\n",
    "        if s.get(\"service\").lower() == \"opendap\":\n",
    "            urls_mod.append(s.get(\"url\")+\"?zg,zghalf,ta,time,level\")\n",
    "\n",
    "urls_mod.sort()\n",
    "\n",
    "#open observation dataset\n",
    "obs = xr.open_dataset(\"sodankyla_sondes_20180201-20180331.nc\")['ta']\n",
    "\n",
    "#set parameters and create list for results\n",
    "errors = [] \n",
    "height = obs['height'].values\n",
    "hours = np.arange(1,13)\n",
    "\n",
    "\n",
    "#calculate error for all model urls in list\n",
    "for url in urls_mod:\n",
    "    df_res = prep_mod(url)\n",
    "    dummy = interpolate_mod(df_res,height)\n",
    "    err = calc_err(dummy,obs,hours)\n",
    "    errors.append(err.T)\n",
    "    \n",
    "\n",
    "#stack the calculated errors along new model number axis\n",
    "#creating 3D datset indexed by time, height and forcast number\n",
    "stacked_errors = np.stack(errors)\n",
    "\n",
    "plottable = calc_median(stacked_errors,hours)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_err(plottable):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    \n",
    "    #set values for time axis\n",
    "    time = np.arange(0,100,6)[1:13]\n",
    "    #create data array with median data as well as height and forcast_lenght\n",
    "    ds = xr.DataArray(plottable,dims=['height','forcast_length'],coords=dict(height = height,forcast_length=time\n",
    "    ))\n",
    "    \n",
    "    #plot the data\n",
    "    plot = plt.contourf(ds.forcast_length,ds.height,ds.values)\n",
    "    \n",
    "    #set plot labels, colors etc\n",
    "    degree_sign = u\"\\N{DEGREE SIGN}\"\n",
    "    plt.colorbar(plot,label=degree_sign+\"C\")\n",
    "    \n",
    "    top = cm.get_cmap('Blues', 127)\n",
    "    bottom = cm.get_cmap('Reds', 127)\n",
    "\n",
    "    newcolors = np.vstack((top(np.linspace(0, 1, 127)),\n",
    "                       bottom(np.linspace(0, 1, 127))))\n",
    "    \n",
    "    \n",
    "    plot.set_cmap(cmap = ListedColormap(newcolors, name='OrangeBlue'))\n",
    "    plt.xticks()\n",
    "    plt.xlabel(\"Forcast length (h)\")\n",
    "    plt.ylabel(\"Altitude (m)\")\n",
    "    plt.title(\"Median forcast error of the temperature\\nSite: Sodankyla, Model: ECMWF - IFS\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_err(plottable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
